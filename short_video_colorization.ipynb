{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "short_video_colorization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA9gRIq-RZ53",
        "colab_type": "code",
        "outputId": "0e5a3cf7-aaa3-4691-9011-b97c188705e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "PATH = '/content/drive/My Drive/dataset/'"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJifWK4ijXxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# while success:\n",
        "#   if not cv2.imwrite('image_{}.jpg'.format(cnt), image):\n",
        "#     print('error')\n",
        "#   success, image = vidcap.read()   \n",
        "#   print('Saved image #', cnt)\n",
        "#   cnt = cnt + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D3lPtoBU8VN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Video is splitted into images and then images are converted into **LAB** color space\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtiGIJo3TiRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, cv2\n",
        "import numpy as np\n",
        "from skimage.color import rgb2lab\n",
        "\n",
        "os.chdir(PATH)\n",
        "\n",
        "vidcap = cv2.VideoCapture('peacock.mp4')\n",
        "success, image = vidcap.read()\n",
        "cnt = 1\n",
        "\n",
        "os.chdir(PATH + 'video_images')\n",
        "video_images = []\n",
        "\n",
        "DIM = (256, 256)\n",
        "while success:\n",
        "  video_images.append(cv2.resize(image, DIM, interpolation = cv2.INTER_AREA) * 1. / 255)\n",
        "  success, image = vidcap.read()   \n",
        "  print('Saved image #', cnt)\n",
        "  cnt = cnt + 1\n",
        "\n",
        "\n",
        "input_images = [(rgb2lab(img)[:,:,0]) for img in video_images]\n",
        "target_images = [(rgb2lab(img)[:,:,1:]) for img in video_images]\n",
        "\n",
        "# print(len(input_images))\n",
        "# print(input_images[0].shape)\n",
        "\n",
        "# print(len(target_images))\n",
        "# print(target_images[0].shape)\n",
        "\n",
        "input_images = np.array(input_images)\n",
        "target_images = np.array(target_images)\n",
        "input_images = input_images.reshape(input_images.shape + (1, ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62aIiSTpju3t",
        "colab_type": "text"
      },
      "source": [
        "> Method to combine **L a b** channels and convert to **RGB**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbqiOMWwj9hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.color import lab2rgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def lab_to_rgb(input, output):\n",
        "  rgb_images = []\n",
        "\n",
        "  for x, y in zip(input, output):\n",
        "    out = np.zeros((256, 256, 3))\n",
        "    out[:,:,0] = x[:,:,0]\n",
        "    out[:,:,1:] = y\n",
        "    rgb_images.append(lab2rgb(out))\n",
        "\n",
        "  return rgb_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbo6QZyKj-Wa",
        "colab_type": "text"
      },
      "source": [
        "> Method to plot specific **images array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvlZyGPUkBWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow_rgb(images):\n",
        "  for img in images:\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxDZSrs8jlOE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "> Model prediction on **L** channel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16GdBCSRRTX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model(PATH + 'autoencoder700.model')\n",
        "result = model.predict(input_images)\n",
        "result *= 128\n",
        "\n",
        "\n",
        "\n",
        "# imshow_rgb(lab_to_rgb(input_images, result))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am7wD-jcsC0O",
        "colab_type": "code",
        "outputId": "99024f78-2b44-4b54-9a69-21e192bf9f12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "images_from_result = lab_to_rgb(input_images, result)\n",
        "\n",
        "os.chdir(PATH)\n",
        "\n",
        "def generate_video(images): \n",
        "  video_name = 'peacock_video_output.avi'\n",
        "  height, width = (256, 256)  \n",
        "\n",
        "  fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
        "  video = cv2.VideoWriter(video_name, fourcc, 30, (height, width))  \n",
        "\n",
        "  # appending the images to the video one by one \n",
        "  for image in images:\n",
        "    video.write(np.uint8(image * 255))\n",
        "    \n",
        "  # deallocating memories taken for window creation \n",
        "  cv2.destroyAllWindows()  \n",
        "  video.release()  # releasing the video generated\n",
        "\n",
        "generate_video(images_from_result)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py:1068: UserWarning: Color data out of range: Z < 0 in 1 pixels\n",
            "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py:1068: UserWarning: Color data out of range: Z < 0 in 2 pixels\n",
            "  return xyz2rgb(lab2xyz(lab, illuminant, observer))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}