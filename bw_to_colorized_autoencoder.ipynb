{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bw_to_colorized-autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNIA6IDcn8-7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Mounting **My Drive** from Google Drive [train and test data is there]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkEyFTJcm5Ig",
        "colab_type": "code",
        "outputId": "6d24e228-6b3c-448e-e4c9-dd5c4f691676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJP3SHkVoILU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Getting train and test data from My Drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNjodP-XoH7l",
        "colab_type": "code",
        "outputId": "fcb3616d-54f6-46d3-afca-836c037c9018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGES_PATH = '/content/gdrive/My Drive/dataset/images/'\n",
        "TRAIN_PATH = IMAGES_PATH + 'train'\n",
        "TEST_PATH = IMAGES_PATH + 'test'\n",
        "\n",
        "data_generator = ImageDataGenerator(rescale = 1.0 / 255)\n",
        "\n",
        "train_generator = data_generator.flow_from_directory(TRAIN_PATH,\n",
        "                                              batch_size = 800,\n",
        "                                              class_mode = None)\n",
        "\n",
        "test_generator = data_generator.flow_from_directory(TEST_PATH,\n",
        "                                              batch_size = 200,\n",
        "                                              class_mode = None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4Xtzupnp2Ry",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "> Preparing train and test data\n",
        "\n",
        "*   **input** consists of **L*** channel\n",
        "*   **output** consists of **a*** and **b*** channels\n",
        "*   **a*** and **b*** channels' values range from -127 to 128, that is why we need to divide them by 128, thereby normalizing their values to -1 and 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqYC8zQ5p2sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.io import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "train_input = [(rgb2lab(img)[:,:,0]) for img in train_generator[0]]\n",
        "train_target = [(rgb2lab(img)[:,:,1:] / 128) for img in train_generator[0]]\n",
        "\n",
        "test_input = [(rgb2lab(img)[:,:,0]) for img in test_generator[0]]\n",
        "test_target = [(rgb2lab(img)[:,:,1:]) for img in test_generator[0]]\n",
        "\n",
        "train_input = np.array(train_input)\n",
        "train_target = np.array(train_target)\n",
        "train_input = train_input.reshape(train_input.shape + (1, ))\n",
        "\n",
        "test_input = np.array(test_input)\n",
        "test_target = np.array(test_target)\n",
        "test_input = test_input.reshape(test_input.shape + (1, ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEjjPT7wtrUF",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Method to combine **L a b** channels and convert to **RGB**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3-rvo3NtqWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lab_to_rgb(input, output):\n",
        "  rgb_images = []\n",
        "\n",
        "  for x, y in zip(input, output):\n",
        "    out = np.zeros((256, 256, 3))\n",
        "    out[:,:,0] = x[:,:,0]\n",
        "    out[:,:,1:] = y\n",
        "    rgb_images.append(lab2rgb(out))\n",
        "\n",
        "  return rgb_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9Cwi7tW017M",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Method to plot specific **images array**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJcwemc_01FB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow_rgb(images):\n",
        "  for img in images:\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRCyMGcwrq1y",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> **ImageColorizer** class definiton,\n",
        "\n",
        "*   **encoder** and **decoder** blocks were created for convenience (code reuse)\n",
        "*   **autoencoder** nn is defined with **tanh** as output function\n",
        "*   **tanh** is used as an activation function, since we need values of range from -1 to 1 (normalized range of **a*** and **b*** channels)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMOa0lUfr9rO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Input, UpSampling2D, LeakyReLU\n",
        "from keras.models import Model\n",
        "\n",
        "class ImageColorizer():\n",
        "  def __init__(self):\n",
        "    self.input_shape = (256, 256, 1)    # L channel\n",
        "    self.output_channels = 2            # A and B channels\n",
        "    self.kernel_size = 3\n",
        "    self.padding = 'same'\n",
        "\n",
        "  # convolutional block for encoder\n",
        "  def encoder_block(self, n_filters, input_layer, is_downsampled = False):\n",
        "    encoder = Conv2D(n_filters, kernel_size = self.kernel_size, padding = self.padding)(input_layer)\n",
        "    if is_downsampled: \n",
        "      encoder = MaxPooling2D()(encoder)\n",
        "      # encoder = Conv2D(n_filters, kernel_size = self.kernel_size, padding = self.padding, strides = 2)(input_layer)\n",
        "    encoder = Activation('relu')(encoder)\n",
        "    return encoder\n",
        "\n",
        "  # convolutional block for decoder\n",
        "  def decoder_block(self, n_filters, input_layer, is_maxpooled = False):\n",
        "    decoder = Conv2D(n_filters, kernel_size = self.kernel_size, padding = self.padding)(input_layer)\n",
        "    if is_maxpooled:\n",
        "      decoder = UpSampling2D()(decoder)\n",
        "    decoder = Activation('relu')(decoder)\n",
        "    return decoder\n",
        "\n",
        "  def build_autoencoder(self):\n",
        "    input_layer = Input(shape = self.input_shape)\n",
        "\n",
        "    # encoder network with input = 256 x 256 x 1\n",
        "    encoder_1 = self.encoder_block(64, input_layer, is_downsampled = True)                      # 128 x 128 x 64\n",
        "    encoder_2 = self.encoder_block(128, encoder_1)                                              # 128 x 128 x 128\n",
        "    encoder_3 = self.encoder_block(128, encoder_2, is_downsampled = True)                       # 64 x 64 x 128\n",
        "    encoder_4 = self.encoder_block(256, encoder_3)                                              # 64 x 64 x 256\n",
        "    encoder_5 = self.encoder_block(256, encoder_4, is_downsampled = True)                       # 32 x 32 x 256\n",
        "    encoder_6 = self.encoder_block(512, encoder_5)                                              # 32 x 32 x 512\n",
        "    encoder_7 = self.encoder_block(512, encoder_6)                                              # 32 x 32 x 512\n",
        "    encoder_8 = self.encoder_block(256, encoder_7)                                              # 32 x 32 x 256\n",
        "\n",
        "\n",
        "    # decoder network\n",
        "    decoder_1 = self.decoder_block(128, encoder_8, is_maxpooled = True)                         # 64 x 64 x 128 \n",
        "    decoder_2 = self.decoder_block(64, decoder_1)                                               # 64 x 64 x 64\n",
        "    decoder_3 = self.decoder_block(32, decoder_2, is_maxpooled = True)                          # 128 x 128 x 32\n",
        "    decoder_4 = self.decoder_block(16, decoder_3)                                               # 128 x 128 x 16\n",
        "    \n",
        "\n",
        "    decoder_5 = Conv2D(self.output_channels, kernel_size = self.kernel_size, padding = self.padding)(decoder_4)    # 256 x 256 x 2\n",
        "    decoder_5 = UpSampling2D()(decoder_5)\n",
        "    output_layer = Activation('tanh')(decoder_5) \n",
        "\n",
        "    model = Model(input_layer, output_layer)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_bRXJMN93VE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "> **Main method** definition\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt7ceSql92tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  colorizer = ImageColorizer()\n",
        "  model = colorizer.build_autoencoder()\n",
        "  # model.summary()\n",
        "  # model.compile(optimizer = 'Adam', loss = 'mse', metrics = ['accuracy'])\n",
        "  # history = model.fit(train_input, train_target, validation_split = 0.05, epochs = 100, batch_size = 32, shuffle = True)\n",
        "  # history = model.fit(train_input, train_target, validation_split = 0.05, epochs = 500, batch_size = 32, shuffle = True)\n",
        "  # history = model.fit(train_input, train_target, validation_split = 0.05, epochs = 700, batch_size = 32, shuffle = True)\n",
        "\n",
        "  # model.save('/content/gdrive/My Drive/dataset/autoencoder.model')\n",
        "  # model.save('/content/gdrive/My Drive/dataset/autoencoder100.model')\n",
        "  # model.save('/content/gdrive/My Drive/dataset/autoencoder700.model')\n",
        "\n",
        "  model = tf.keras.models.load_model('/content/gdrive/My Drive/dataset/autoencoder700.model')\n",
        "\n",
        "  result = model.predict(test_input)\n",
        "  result = result * 128                 # values in range from -1 to 1 due to tanh activation function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSjjmmXUMYh_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Saving the **history** object in the specified file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87EWBK2jL-q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "ROOT_PATH = '/content/gdrive/My Drive/dataset/'\n",
        "\n",
        "def save_history(history_filename):\n",
        "  f = open(ROOT_PATH + history_filename, 'wb')\n",
        "  pickle.dump(history.history, f)\n",
        "  f.close()\n",
        "\n",
        "# save_history('history100.pckl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTzR5His9aaI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Uploading the **history** object from the specified file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nanLXwy89gm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_history(history_filename):\n",
        "  f = open(ROOT_PATH + history_filename, 'rb')\n",
        "  history = pickle.load(f)\n",
        "  f.close()\n",
        "  return history\n",
        "\n",
        "# history = load_history('history100.pckl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "217kvCLHiltf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Plotting training and validation loss values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IrwIb2YiAZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.figure(figsize=(12,6))\n",
        "  plt.plot(history['loss'])\n",
        "  plt.plot(history['val_loss'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "plot_loss(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRCp6jobGZHP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Plot training and validation accuracy values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-cNnLBVACty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accuracy(history):\n",
        "  plt.figure(figsize=(12,6))\n",
        "  plt.plot(history['accuracy'])\n",
        "  plt.plot(history['val_accuracy'])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "plot_accuracy(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmlKuBTgrv0r",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> Function to **compare** greyscale image, resulting image and real image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmi43UfUy7cW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performance_result(output):\n",
        "  greyscale_images = lab_to_rgb(test_input, np.zeros(output.shape))\n",
        "  output_images = lab_to_rgb(test_input, output)\n",
        "  real_images = lab_to_rgb(test_input, test_target)\n",
        "  images = greyscale_images + output_images + real_images\n",
        "\n",
        "  for gi, oi, ri in zip(greyscale_images, output_images, real_images):\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(gi)\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(oi)\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(ri)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "performance_result(result)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}